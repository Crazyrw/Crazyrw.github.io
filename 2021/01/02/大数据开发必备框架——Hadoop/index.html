

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="梦想很珍贵，努力特别酷。-xback">
  <meta name="author" content="Crazyrw">
  <meta name="keywords" content="">
  <title>大数据开发必备框架——hadoop(持续更新中) - Crazyrw&#39;s blog</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.5.3/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.1.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.5","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"copy_btn":true,"image_zoom":{"enable":true},"lazyload":{"enable":true,"onlypost":false},"web_analytics":{"enable":true,"baidu":"7d2fd3d56f2287a0bda354d214258de6","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.2.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Crazyrw's Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/images/bg/post.webp') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="大数据开发必备框架——hadoop(持续更新中)">
              
            </span>

            <p class="h2"><a id="rainbow" href=''>🌈 获取中...</a></p>
            <script>
              fetch('https://api.eatrice.top')
                .then(response => response.json())
                .then(data => {
                  var rainbow = document.getElementById('rainbow');
                  rainbow.innerHTML = data.Content;
                  rainbow.href = "https://rainbow.eatrice.top/?ID=" + data.ID;
                })
                .catch(console.error)
              </script>


            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-01-02 11:05" pubdate>
        January 2, 2021 am
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      5.1k 字
    </span>
  

  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">大数据开发必备框架——hadoop(持续更新中)</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：a few seconds ago
                
              </p>
            
            <div class="markdown-body">
              <h1 id="大数据技术——Hadoop"><a href="#大数据技术——Hadoop" class="headerlink" title="大数据技术——Hadoop"></a>大数据技术——Hadoop</h1><h2 id="1-大数据概论"><a href="#1-大数据概论" class="headerlink" title="1.大数据概论"></a>1.大数据概论</h2><h3 id="1-1大数据概念"><a href="#1-1大数据概念" class="headerlink" title="1.1大数据概念"></a>1.1大数据概念</h3><blockquote>
<p>大数据（big data），IT行业术语，是指无法<strong>在一定时间范围内</strong>用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的<strong>海量、高增长率和多样化的信息资产。</strong></p>
<p>——百度百科</p>
</blockquote>
<p> 在mysql中,每个数据库最多可创建20亿个表,一个表允许定义1024列,每行的最大长度为8092字节(不包括文本和图像类型的长度)。</p>
<p>美团 5000台起，BAT上万台服务器。</p>
<p>按顺序给出数据存储单位：bit Byte KB MB GB <span style="color:rgb(255, 0, 255);">TB PB EB</span> ZB YB BB NB DB</p>
<p>1Byte = 8bit   1KB = 1024Byte</p>
<p>1MB = 1024KB    1GB = 1024MB</p>
<p><span style="color:rgb(255, 0, 255);">1TB = 1024GB    1PB = 1024TB</span></p>
<p>BAT和头条基本上能达到EB。</p>
<p><strong>大数据主要解决的问题：海量数据的<span style="color:rgb(255, 0, 255);">存储</span>和海量数据的分析计算问题。</strong></p>
<h3 id="1-2大数据特点（4V）"><a href="#1-2大数据特点（4V）" class="headerlink" title="1.2大数据特点（4V）"></a>1.2大数据特点（4V）</h3><ul>
<li><p>Volume(大量):大企业的数据量接近EB量级。</p>
</li>
<li><p>Velocity(高速):在海量数据面前处理数据的效率就是企业的声明</p>
</li>
<li><p>Variety(多样)</p>
<p>数据分为<strong>结构化数据和非结构化数据</strong>。相对于以往便于存储的<span style="color:rgb(255, 0, 255);">以数据库/文本为主的结构化数据</span>，<span style="color:rgb(255, 0, 255);">非结构化数据</span>越来越多，包括<span style="color:rgb(255, 0, 255);">网络日志、音频、视频、图片、地理位置信息</span>等，这些多类型的数据对数据的处理能力提出了更高要求。</p>
</li>
<li><p>Value(低价值密度)</p>
<p>价值密度的高低与数据总量的大小成反比。</p>
<p>因此，如果快速对有价值数据“提纯”称为目前大数据背景下待解决的难题。</p>
</li>
</ul>
<h3 id="1-3大数据应用场景"><a href="#1-3大数据应用场景" class="headerlink" title="1.3大数据应用场景"></a>1.3大数据应用场景</h3><ul>
<li>物流仓储：大数据分析系统助力商家精细化运营、提升销量、节约成本。</li>
<li>零售：分析用户消费习惯，为用户购买商品提供方便，从而提升商品销量。经典案例：纸尿布+啤酒</li>
<li>旅游：深度结合大数据能力与旅游行业需求，共建旅游产业智慧管理、智慧服务和智慧营销的未来。</li>
<li>电商广告推荐：给用户推荐可能喜欢的商品</li>
<li>保险：海量数据挖掘及风险预测，助力保险行业精准营销，提升精细化定价能力。  </li>
<li>金融：多维度体现用户特征，帮助金融机构推荐优质客户，防范欺诈风险。</li>
<li>房产：大数据全面助力房地产行业，打造精准投策与营销，选出更合适的地，建造更合适的楼，卖给更合适的人。</li>
<li>人工智能：机器人工厂、足球机器人、情感机器人、自动驾驶</li>
</ul>
<h3 id="1-5大数据部门业务流程分析"><a href="#1-5大数据部门业务流程分析" class="headerlink" title="1.5大数据部门业务流程分析"></a>1.5大数据部门业务流程分析</h3><p>产品人员提需求（统计总用户数、日活跃用户数、回流用户数）</p>
<p>-&gt;数据部门搭建数据平台、分析数据指标</p>
<p>-&gt;数据可视化（报表展示、邮件发送、大屏幕展示等）【JavaEE】</p>
<h3 id="1-6大数据部门组织结构"><a href="#1-6大数据部门组织结构" class="headerlink" title="1.6大数据部门组织结构"></a>1.6大数据部门组织结构</h3><p>![组织结构图 (1)](/images/大数据开发必备框架——Hadoop/组织结构图 (1).png)</p>
<h2 id="2-从Hadoop框架讨论大数据生态"><a href="#2-从Hadoop框架讨论大数据生态" class="headerlink" title="2.从Hadoop框架讨论大数据生态"></a>2.从Hadoop框架讨论大数据生态</h2><h3 id="2-1Hadoop简介"><a href="#2-1Hadoop简介" class="headerlink" title="2.1Hadoop简介"></a>2.1Hadoop简介</h3><ul>
<li>Hadoop是一个由Apache基金会所开发的<strong>分布式系统基础架构</strong>。</li>
<li>主要解决，海量数据的存储和海量数据的分析计算问题。</li>
</ul>
<p>Google是Hadoop的思想之源（Google在大数据方面的三篇论文）</p>
<ul>
<li>GFS -&gt; HDFS</li>
<li>Map-Reduce -&gt; MR</li>
<li>BigTable -&gt; HBase</li>
</ul>
<p>Hadoop的三大发行版本：Apache、Cloudera、Hortonworks</p>
<ul>
<li>Apache版本最原始（最基础）的版本，对于入门学习最好。（版本兼容问题，需要自己去解决）</li>
<li>Cloudera在大型互联网企业中用的比较多，CDH版本。（有利于解决版本兼容问题，一整套）</li>
<li>Hortonworks：文档较好，但是出现什么问题，需要收费</li>
</ul>
<p>Hadoop创始人加入了Cloudera公司。</p>
<h3 id="2-2Hadoop的优势（4高）"><a href="#2-2Hadoop的优势（4高）" class="headerlink" title="2.2Hadoop的优势（4高）"></a>2.2Hadoop的优势（4高）</h3><ul>
<li>高可靠性：Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失。</li>
<li>高扩展性：在集群间分配任务数据，可方便的扩展数以千计的节点。</li>
<li>高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。</li>
<li>高容错性：能够自动将失败的任务重新分配。</li>
</ul>
<h3 id="2-3Hadoop1-x和Hadoop2-x的区别"><a href="#2-3Hadoop1-x和Hadoop2-x的区别" class="headerlink" title="2.3Hadoop1.x和Hadoop2.x的区别"></a>2.3Hadoop1.x和Hadoop2.x的区别</h3><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210102152841372.png" srcset="/img/loading.gif" alt="image-20210102152841372"></p>
<p>在Hadoop1.x时代，Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度，耦合性较大，在Hadoop2.x时代，增加了Yarn。Yarn只负责资源的调度，MapeReduce只负责运算。</p>
<p>我看的视频教程是2018年的，Hadoop版本是2.x的，现在2021了，我们都是使用的3.x，在之后的学习中，我打算直接采用Hadoop3进行学习，应该差别不大，随时更新吧。</p>
<h3 id="2-4Hadoop3-x和Hadoop2-x的主要区别"><a href="#2-4Hadoop3-x和Hadoop2-x的主要区别" class="headerlink" title="2.4Hadoop3.x和Hadoop2.x的主要区别"></a>2.4Hadoop3.x和Hadoop2.x的主要区别</h3><p>最低支持Java版本从7升到了8</p>
<p>引入了纠删码（Erasure Coding，EC）</p>
<p>主要解决数据量大到一定程度磁盘空间存储能力不足的问题。</p>
<p>EC技术，是一种数据保护技术，最早用于通信行业中数据传输中的数据恢复，是一种编码容错技术。</p>
<p>它通过在原始数据中加入新的校验数据，使得各个部分的数据产生关联性。在一定范围的数据出错情况下，通过纠删码技术都可以进行恢复。</p>
<p>Hadoop3.x之前，HDFS存储方式为每一份数据存储3份，这也使得存储利用率为1/3.</p>
<p>Hadoop3.x引入EC技术，实现1份数据+0.5份冗余校验数据存储方式。</p>
<p>与副本相比，纠删码是一种更节省空间的数据持久化存储方法。标准编码（比如Reed-Solomon(10,4)）会有1.4倍的空间开销，然而HDFS副本会有3倍的空间开销。</p>
<p>因为纠删码额外开销主要是在重建和执行远程读，它传统用于存储冷数据，即不经常访问的数据，当部署这个新特性时用户应该考虑纠删码的网络和CPU开销。</p>
<p>重写了shell脚本</p>
<ul>
<li>增加了参数冲突检测，避免重复定义和冗余参数</li>
<li>CLASSPATH, JAVA_LIBRARY_PATH, and LD_LIBRARY_PATH等参数的去重，缩短环境变量 </li>
<li>shell脚本重构，将更多的代码加入function中，提供重载，删除重复代码，便于测试</li>
<li>脚本清理和简化</li>
<li>尽可能与当前系统保持兼容</li>
<li>提供一份Hadoop环境变量列表</li>
</ul>
<p>默认端口的修改</p>
<p>在hadoop3.x之前，多个hadoop服务的默认端口都属于Linux的临时端口（32768-61000）。这就意味着用户的服务在启动可能因为和其他应用程序端口冲突而无法启动。现在这些可能会产生冲突的端口已经不再属于临时端口范围，这些端口的改变会影响NameNode,Secondary NameNode,DataNode以及KMS。与此同时，官方文档也进行了相应的改变，具体可以参见以及HADOOP-12811。</p>
<p>NameNode ports:50470–&gt;9871,50070–&gt;9870,8020–&gt;9820</p>
<p>Secondary NN ports:50091–&gt;9869,50090 –&gt; 9868</p>
<p>DataNode ports:50020 –&gt; 9867, 50010–&gt; 9866, 50475 –&gt; 9865, 50075 –&gt; 9864</p>
<p>KMS server ports: 6000 –&gt; 9600 (原先的16000与HMaster端口冲突)                                                   </p>
<p>//其他的不同点，如果我之后在学习中遇到的话，我会在这里进行更新一下。</p>
<h3 id="2-5-Hadoop组成（面试重点）"><a href="#2-5-Hadoop组成（面试重点）" class="headerlink" title="2.5 Hadoop组成（面试重点）"></a>2.5 Hadoop组成（面试重点）</h3><h4 id="2-5-1-HDFS架构概述"><a href="#2-5-1-HDFS架构概述" class="headerlink" title="2.5.1 HDFS架构概述"></a>2.5.1 HDFS架构概述</h4><ol>
<li>NameNode(nn):存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。</li>
<li>DataNode(dn):在本地文件系统存储文件块数据，以及块数据的校验和。</li>
<li>Secondary NameNode(2nn):用来监视HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</li>
</ol>
<h4 id="2-5-2-Yarn架构概述"><a href="#2-5-2-Yarn架构概述" class="headerlink" title="2.5.2 Yarn架构概述"></a>2.5.2 Yarn架构概述</h4><p>YARN 也是典型的 Master-Slave 架构，Master 称为 ResourceManager(RM), Slave 称为 NodeManager(NM)。</p>
<p><b><span style="color:rgb(255, 0, 255);">RM负责接收用户提交的任务，并且决定为任务分配多少资源和调度到哪个NM去执行；NM是真正执行任务的节点，周期性的向RM汇报自己的资源使用情况并领取R,分配的任务，负责启动和停止任务相关的进程等工作。</span></b></p>
<hr>
<p><strong>相关名词解释：</strong></p>
<ul>
<li><strong>资源：</strong> 在YARN的语境中，资源特指计算资源，包括CPU和内存。计算机的每个进程都会占用一定的CPU和内存，任务需要先向RM申请到资源后才能获准在NM上启动自己的进程。</li>
<li><strong>队列：</strong> YARN 将整个集群的资源划分为队列，每个用户的任务必须提交到指定队列。同时限制每个队列的大小，防止某个用户的任务占用整个集群，影响了其他用户的使用。</li>
<li><strong>Container:</strong> 任务申请资源后在NM上启动的进程统称为Container。比如在 MapReduce 中可以是 Mapper 或 Reducer，在 Spark 中可以是 Driver 或 Executor。</li>
</ul>
<hr>
<ol>
<li><p>ResourceManager（RM）主要作用</p>
<ul>
<li>处理客户端需求</li>
<li>监控NodeManager</li>
<li>启动或监控ApplicationMaster</li>
<li>资源的分配与调度</li>
</ul>
<p>包含ResourceScheduler、Application Manager。</p>
<p>ResourceScheduler-&gt;资源调度器，根据节点的容量、队列情况、为应用程序分配资源</p>
<p>Application Manager-&gt;应用程序管理器，负责接收Client端传输的job请求。</p>
</li>
<li><p>NodeManager(NM)主要作用</p>
<ul>
<li>管理单个节点上的资源</li>
<li>处理来自ResourceManager的命令</li>
<li>处理来自ApplicationMaster的命令</li>
</ul>
<p>本节点上的资源管理和任务管理。</p>
<p>定时向ResourceManager汇报本节点上的资源使用情况和各个Container的运行情况。</p>
<p>接收和处理来自ResourceManager的  Container启动和停止的各种命令。</p>
<p>处理来自ApplicationMaster的指令。比如启动MapTask和ReduceTask指令。</p>
</li>
<li><p>ApplicationMaster(AM)的作用</p>
<ul>
<li>负责数据的切分</li>
<li>为应用程序申请资源并分配给内部的任务</li>
<li>任务的监控与容错（当某些Task运行错误时，进行容错处理）</li>
</ul>
</li>
</ol>
<p>每个应用程序对应一个ApplicationMaster，负责单个应用程序的管理。</p>
<p>为应用程序向ResourceManager申请资源(Container)，并分配内部任务(MapTask和ReduceTask)与NodeManager通信来启动/停止任务，Task都是运行在Container中的。</p>
<ol start="3">
<li>Container<ul>
<li>Container是Yarn中的资源抽象，它封装了某个节点的多维度资源，如内存、CPU、磁盘、网络等。</li>
</ul>
</li>
</ol>
<p>Container类似于一个虚拟机，可以在上面执行任务。</p>
<p>任务申请资源后在NM上启动的进程统称为Container。</p>
<hr>
<p><span style="color:rgb(255, 0, 255);"><strong>YARN的工作机制：</strong></span></p>
<p>（1）MR程序提交到客户端所在的节点。</p>
<p>（2）YarnRunner向ResourceManager申请一个Application。</p>
<p>（3）RM将该应用程序的资源路径返回给YarnRunner。</p>
<p>（4）该程序将运行所需资源提交到HDFS上。</p>
<p>（5）程序资源提交完毕后，申请运行mrAppMaster。</p>
<p>（6）RM将用户的请求初始化成一个Task。</p>
<p>（7）其中一个NodeManager领取到Task任务。</p>
<p>（8）该NodeManager创建容器Container，并产生MRAppmaster。</p>
<p>（9）Container从HDFS上拷贝资源到本地。</p>
<p>（10）MRAppmaster向RM 申请运行MapTask资源。</p>
<p>（11）RM将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。</p>
<p>（12）MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序。</p>
<p>（13）MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask。</p>
<p>（14）ReduceTask向MapTask获取相应分区的数据。</p>
<p>（15）程序运行完毕后，MR会向RM申请注销自己。</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/2.1.png" srcset="/img/loading.gif" alt="2.1"></p>
<h3 id="2-5-3-MapReduce架构概述"><a href="#2-5-3-MapReduce架构概述" class="headerlink" title="2.5.3 MapReduce架构概述"></a>2.5.3 MapReduce架构概述</h3><p>MapReduce常用于对大规模数据集（大于1TB）的并行计算，或对大数据进行加工、挖掘和优化等处理。MapReduce将并行计算过程高度抽象到了两个函数map和reduce中，程序员只需要负责map和reduce函数的编写工作，而并行程序中的其他复杂问题（如分布式存储、工作调度、负责均衡、容错处理等）均可由MapReduce框架代为处理，程序员完全不用操心。</p>
<hr>
<p>MapReduce的技术特征：</p>
<ul>
<li>横向扩展，而非纵向扩展。</li>
<li>失效被认为是常态</li>
<li>将处理向数据迁移</li>
<li>顺序处理数据</li>
<li>隐藏系统层细节</li>
<li>平滑无缝的可扩展性</li>
</ul>
<hr>
<p>MapReduce的设计思想：</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/482819-20200317191426229-1574114756.png" srcset="/img/loading.gif" alt="img"></p>
<p>例如，求和：1+2+3+4+5+6+7+8+9+10=?，执行原理如下：</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/482819-20200317191453256-147234515.png" srcset="/img/loading.gif" alt="img"></p>
<hr>
<p><strong>MapReduce的工作原理（自己总结的）</strong></p>
<p>MapReduce处理大数据集的计算过程是将大数据集分解成 成百上千的小数据集，每个（或若干个）数据集分别由集群中一个节点进行处理并生成中间结果，然后这些中间结果会进行合并，从而得到最终结果。</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/482819-20200317191532115-1901433424.png" srcset="/img/loading.gif" alt="img"></p>
<hr>
<p><strong>MapReduce任务流程：</strong></p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/482819-20200317191550069-137570022.png" srcset="/img/loading.gif" alt="img"></p>
<p>补充一下：上一部分说Yarn时，出现的MapTask就是Map的计算过程，同理，ReduceTask就是Reduce过程。</p>
<h3 id="2-6-大数据技术生态体系"><a href="#2-6-大数据技术生态体系" class="headerlink" title="2.6 大数据技术生态体系"></a>2.6 大数据技术生态体系</h3><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/1.png" srcset="/img/loading.gif" alt="1"></p>
<p>说明：</p>
<ul>
<li><p><strong>MapReduce离线计算、Spark Core内存计算都是离线计算。</strong></p>
</li>
<li><p>Hive的底层其实就是MapReduce。为JavaEE诞生的。</p>
</li>
<li><p>Spark Sql和Hive很类似。</p>
</li>
<li><p>Spark Streaming：准实时计算，批处理。而Storm就是实时计算，来了就计算。</p>
</li>
<li><p><span style="color:rgb(255, 0, 255);">现在很多大型企业已经从Storm转向Flink了。</span></p>
</li>
</ul>
<p>相关名词的介绍：</p>
<ul>
<li>Sqoop: Sqoop是一款开源软件，主要用在Hadoop、Hive与传统数据库(MySql)间进行数据传递，<strong>可以将一个关系型数据库(如MySQL、Oracle等)中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导入到关系型数据库。</strong></li>
<li>Flume: Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集，聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接收方（可定制）的能力。</li>
<li>HBase: HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适用于非结构化数据存储的数据库。K-V数据对进行存储。</li>
<li>Kafka: Kafka是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等。主要应用场景：日志收集系统和消息系统。<ul>
<li>以时间复杂度O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。</li>
<li>高吞吐率：即使在非常廉价的商品机器上也能做到单机支持每秒100K条消息的传输。</li>
<li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个分区内的消息顺序传输。</li>
<li>同时支持离线数据处理和实时数据处理。</li>
<li>Scale out:支持在线水平扩展</li>
</ul>
</li>
<li>Spark: Spark是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大数据进行计算。Spark实际上是对Hadoop的补充，可以在Hadoop文件系统中并行运行。<ul>
<li>Spark支持交互式计算和复杂算法</li>
<li>Spark是一个通用引擎，可用它完成各种各样的运算，包括SQL查询、文本处理、机器学习等，而在 Spark 出现之前，我们一般需要学习各种各样的引擎来分别处理这些需求。</li>
</ul>
</li>
<li>Oozie: Oozie是一个管理Hadoop作业(job)的工作流程调度管理系统。</li>
<li>Azkaban: Azkaban是一个批量工作流任务调度器，用于在一个工作流内以一个特定的顺序运作一组工作和流程。是一套简单的任务调度服务。</li>
</ul>
<hr>
<p><strong>推荐系统项目框架：</strong></p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/20181203132727633.png" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103121325314.png" srcset="/img/loading.gif" alt="image-20210103121325314"></p>
<h2 id="3-Hadoop运行环境搭建（开发重点）"><a href="#3-Hadoop运行环境搭建（开发重点）" class="headerlink" title="3.Hadoop运行环境搭建（开发重点）"></a>3.Hadoop运行环境搭建（开发重点）</h2><p>准备工作： </p>
<p>工具：VMware Workstation Pro(<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV17g4y1v72V?from=search&seid=13236918558372824969">安装参考视频</a>)、四台虚拟机(CentOS7)、SecureCRT 8.1(用于远程连接)。</p>
<p>虚拟机的配置如下：</p>
<table>
<thead>
<tr>
<th>hostname</th>
<th>IP地址</th>
</tr>
</thead>
<tbody><tr>
<td>hadoop100</td>
<td>192.168.123.100</td>
</tr>
<tr>
<td>hadoop101</td>
<td>192.168.123.101</td>
</tr>
<tr>
<td>hadoop102</td>
<td>192.168.123.102</td>
</tr>
<tr>
<td>hadoop103</td>
<td>192.168.123.103</td>
</tr>
</tbody></table>
<hr>
<p><strong>四台虚拟机的环境配置：</strong></p>
<ul>
<li>IP地址、hostname按照上述表格中的配置。</li>
<li>设置网卡自启动。</li>
<li>关闭防火墙</li>
<li>创建user01用户，并配置user01用户拥有root权限。</li>
</ul>
<p>创建完其中一个虚拟机之后，其余的虚拟机直接克隆就可，具体的流程自行百度。</p>
<ol>
<li><p>修改IP地址，vim /etc/sysconfig/network-scripts/ifcfg-ens33</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103193626315.png" srcset="/img/loading.gif" alt="image-20210103193626315"></p>
</li>
<li><p>修改主机名称 vim /etc/hostname</p>
<p>修改/etc/hosts文件：</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103194116695.png" srcset="/img/loading.gif" alt="image-20210103194116695"></p>
</li>
<li><p>测试各个主机之间是否畅通，使用ping命令。</p>
</li>
<li><p>之后重启虚拟机就可，reboot。</p>
</li>
<li><p>配置user01用户拥有root权限。</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103194836331.png" srcset="/img/loading.gif" alt="image-20210103194836331"></p>
</li>
<li><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103194814970.png" srcset="/img/loading.gif" alt="image-20210103194814970"></p>
</li>
<li><p>在/opt目录下创建文件夹,配置JDK，Hadoop</p>
<ul>
<li><p>在/opt目录下创建module,software文件夹</p>
<p>software：存放所有的jar包</p>
<p>module：将所有的jar解压到这里。</p>
<p>sudo mkdir software</p>
<p>sudo mkdir module</p>
<p>使用sudo创建的文件夹属于root用户，因此我们还需要修改一下所属者和所属组：sudo chown user01:user01 module/ software/</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103195419374.png" srcset="/img/loading.gif" alt="image-20210103195419374"></p>
</li>
<li><p>将所需要的文件传输到虚拟机</p>
<p>快捷键：Alt+P,进入到/opt/software目录，之后通过拖拽的方式即可传输。</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103195905787.png" srcset="/img/loading.gif" alt="image-20210103195905787"></p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103200008540.png" srcset="/img/loading.gif" alt="image-20210103200008540"></p>
</li>
<li><p>将传输的文件解压到module文件夹下</p>
<p>tar -zxvf 所需要解压的文件 -C /opt/module</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103200158613.png" srcset="/img/loading.gif" alt="image-20210103200158613"></p>
</li>
<li><p>配置JDK</p>
<p>进入到jdk的文件中，获取jdk的路径，并复制。</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103200256716.png" srcset="/img/loading.gif" alt="image-20210103200256716"></p>
<p>进入profile文件夹，修改环境变量。</p>
<p>sudo vim /etc/profile</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103200914857.png" srcset="/img/loading.gif" alt="image-20210103200914857"></p>
<p>此时还没配置好，需要再执行source /etc/profile</p>
<p>最后判断java环境是否配置好，java -version,出现下面的界面就代表已经配置好。</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103200650944.png" srcset="/img/loading.gif" alt="image-20210103200650944"></p>
</li>
<li><p>配置hadoop</p>
<p>也是需要配置环境变量，和上一步一样.</p>
<p>sudo vim /etc/profile</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103200940103.png" srcset="/img/loading.gif" alt="image-20210103200940103"></p>
<p>执行source /etc/profile</p>
<p>检验hadoop是否配置成功,hadoop.出现一大堆命令就代表可以了</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103201125035.png" srcset="/img/loading.gif" alt="image-20210103201125035"></p>
</li>
</ul>
</li>
</ol>
<hr>
<p><strong>SecureCRT远程连接</strong></p>
<p>SecureCRT进行远程连接时，如果不想用IP连接，可以使用hostname，但是需要配置本地的host文件，进行映射。</p>
<p>具体路径：</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103191822894.png" srcset="/img/loading.gif" alt="image-20210103191822894"></p>
<p>修改：</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103192130395.png" srcset="/img/loading.gif" alt="image-20210103192130395"></p>
<p>连接：</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103191921903.png" srcset="/img/loading.gif" alt="image-20210103191921903"></p>
<p>之后点击输入密码即可。</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103192001966.png" srcset="/img/loading.gif" alt="image-20210103192001966"></p>
<hr>
<h3 id="出现的问题"><a href="#出现的问题" class="headerlink" title="出现的问题"></a>出现的问题</h3><p>打开虚拟机发现不显示网卡ens33，不显示IP地址。</p>
<p>解决方法：有可能是和 NetworkManager 服务有冲突，直接关闭 NetworkManger 服务就好了， service NetworkManager stop，并且禁止开机启动 chkconfig NetworkManager off 。之后重启就好了，service network restart 。</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103191122833.png" srcset="/img/loading.gif" alt="image-20210103191122833"></p>
<h2 id="4-Hadoop运行模式"><a href="#4-Hadoop运行模式" class="headerlink" title="4.Hadoop运行模式"></a>4.Hadoop运行模式</h2><p>Hadoop运行模式包括：本地模式、伪分布式模式和完全分布式模式。</p>
<h3 id="4-1本地运行模式"><a href="#4-1本地运行模式" class="headerlink" title="4.1本地运行模式"></a>4.1本地运行模式</h3><p>本地模式下，hadoop不需要其他的配置。</p>
<h4 id="4-1-1-官方Grep案例"><a href="#4-1-1-官方Grep案例" class="headerlink" title="4.1.1 官方Grep案例"></a>4.1.1 官方Grep案例</h4><p>切换到hadoop目录下，创建input文件夹：mkdir input</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103205417416.png" srcset="/img/loading.gif" alt="image-20210103205417416"></p>
<p>将etc/hadoop/下的所有xml文件复制到input文件夹下：</p>
<p>cp etc/hadoop/*.xml input/</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103205529401.png" srcset="/img/loading.gif" alt="image-20210103205529401"></p>
<p>运行官方案例Grep:</p>
<p>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.0.jar grep input output ‘dfs[a-z]+’</p>
<p>解释：</p>
<ul>
<li>hadoop:启动命令</li>
<li>jar: 以jar方式运行</li>
<li>input:输入目录</li>
<li>output:输出目录，<span style="color:rgb(255, 0, 255);">注意：output不能提前创建，否则会抛出文件已经存在的异常。</span></li>
<li>dfs[a-z]+:正则表达式，表示匹配dfs开头的。</li>
</ul>
<p>查看结果：</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103212327242.png" srcset="/img/loading.gif" alt="image-20210103212327242"></p>
<h4 id="4-1-2-官方WordCount案例"><a href="#4-1-2-官方WordCount案例" class="headerlink" title="4.1.2 官方WordCount案例"></a>4.1.2 官方WordCount案例</h4><p>切换到hadoop文件夹下。</p>
<p>创建文件夹wcinput:mkdir wcinput</p>
<p>进入wcinput文件夹，创建文件wc.input:touch wc.input</p>
<p>向文件写入数据：vim wc.input</p>
<pre><code class="hljs ebnf"><span class="hljs-attribute">hadoop yarn</span>
<span class="hljs-attribute">hadoop mapreduce</span>
<span class="hljs-attribute">abcdabc</span>
<span class="hljs-attribute">admin a</span></code></pre>

<p><span style="color:rgb(255, 0, 255);">同样需要注意的是：输出文件夹不能提前创建。</span></p>
<p>运行案例：</p>
<p>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.0.jar wordcount wcinput wcoutput</p>
<p>运行结果：</p>
<p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%BF%85%E5%A4%87%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Hadoop/image-20210103213006714.png" srcset="/img/loading.gif" alt="image-20210103213006714"></p>
<h3 id="4-2伪分布式运行模式"><a href="#4-2伪分布式运行模式" class="headerlink" title="4.2伪分布式运行模式"></a>4.2伪分布式运行模式</h3><p><span style="color:rgb(255, 0, 255);">注意：启用伪分布式模式后，本地模式就不能用了。</span></p>
<p>原因是：本地模式用的是File协议，而伪分布式用的是hdfs协议。</p>
<p>伪分布式模式是以集群方式搭建的，实际是完全分布式模式。适用于 电脑配置比较低，没有多台电脑的程序员。（只有一个服务器节点，其余都和完全分布式配置相同）</p>
<p>//明天继续更新，今天累了<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41813208/article/details/100706918">https://blog.csdn.net/qq_41813208/article/details/100706918</a></p>
<h3 id="4-3完全分布式运行模式（开发重点）"><a href="#4-3完全分布式运行模式（开发重点）" class="headerlink" title="4.3完全分布式运行模式（开发重点）"></a>4.3完全分布式运行模式（开发重点）</h3><h2 id="5-Hadoop编译源码（面试重点）"><a href="#5-Hadoop编译源码（面试重点）" class="headerlink" title="5.Hadoop编译源码（面试重点）"></a>5.Hadoop编译源码（面试重点）</h2><h2 id="6-常见错误及解决方案"><a href="#6-常见错误及解决方案" class="headerlink" title="6.常见错误及解决方案"></a>6.常见错误及解决方案</h2>
            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/12/27/fail-fast%E5%92%8Cfail-safe/">
                        <span class="hidden-mobile">fail-fast和fail-safe</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  

  
</footer>

<!-- SCRIPTS -->

  <script  src="https://cdn.staticfile.org/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":200})
    NProgress.start()
    document.addEventListener('DOMContentLoaded', function() {
      window.NProgress && window.NProgress.inc();
    })
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.staticfile.org/jquery/3.5.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.5.3/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script  src="https://cdn.staticfile.org/tocbot/4.12.0/tocbot.min.js" ></script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>


  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      var inputArea = document.querySelector("#local-search-input");
      inputArea.onclick = function () {
        searchFunc(path, 'local-search-input', 'local-search-result');
        this.onclick = null
      }
    })()
  </script>












  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?7d2fd3d56f2287a0bda354d214258de6";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>



</body>
</html>
